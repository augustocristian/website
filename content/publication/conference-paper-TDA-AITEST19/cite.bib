@inproceedings{augusto_test-driven_2018,
abstract = {In recent years, data published and shared with third parties to develop artificial intelligence (AI) tools and services has significantly increased. When there are regulatory or internal requirements regarding privacy of data, anonymization techniques are used to maintain privacy by transforming the data. The side-effect is that the anonymization may lead to useless data to train and test the AI because it is highly dependent on the quality of the data. To overcome this problem, we propose a test-driven anonymization approach for artificial intelligence tools. The approach tests different anonymization efforts to achieve a trade-off in terms of privacy (non-functional quality) and functional suitability of the artificial intelligence technique (functional quality). The approach has been validated by means of two real-life datasets in the domains of healthcare and health insurance. Each of these datasets is anonymized with several privacy protections and then used to train classification AIs. The results show how we can anonymize the data to achieve an adequate functional suitability in the AI context while maintaining the privacy of the anonymized data as high as possible.},
author = {Augusto, Cristian and Mor{\'{a}}n, Jes{\'{u}}s and {De La Riva}, Claudio and Tuya, Javier},
booktitle = {Proceedings - 2019 IEEE International Conference on Artificial Intelligence Testing, AITest 2019},
doi = {10.1109/AITest.2019.00011},
file = {:C\:/Users/augus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Augusto et al. - 2019 - Test-driven anonymization for artificial intelligence.pdf:pdf},
isbn = {9781728104928},
keywords = {Anonymization,Artificial Intelligence,K-Anonymity,Software Testing},
mendeley-groups = {02_TDA/21_TDA_PREFUGE,2019_AITEST19},
pages = {103--110},
shorttitle = {Test-driven Anonymization for Artificial Intellige},
title = {{Test-driven anonymization for artificial intelligence}},
year = {2019}
}